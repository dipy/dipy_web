{"parents": [{"link": "../../documentation/", "title": "Documentation"}, {"link": "../", "title": "API Reference"}], "prev": {"link": "../dipy.io/", "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">io</span></code>"}, "next": {"link": "../dipy.reconst/", "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">reconst</span></code>"}, "title": "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code>", "meta": {}, "body": "<section id=\"module-dipy.nn\">\n<span id=\"nn\"></span><h1><code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code><a class=\"headerlink\" href=\"#module-dipy.nn\" title=\"Permalink to this heading\">\u00b6</a></h1>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n</tbody>\n</table>\n<section id=\"module-dipy.nn.cnn_1d_denoising\">\n<span id=\"module-nn-cnn-1d-denoising\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.cnn_1d_denoising</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.cnn_1d_denoising\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<section id=\"title-denoising-diffusion-weighted-imaging-data-using-cnn\">\n<h3>Title : Denoising diffusion weighted imaging data using CNN<a class=\"headerlink\" href=\"#title-denoising-diffusion-weighted-imaging-data-using-cnn\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<p>Obtaining tissue microstructure measurements from diffusion weighted imaging\n(DWI) with multiple, high b-values is crucial. However, the high noise levels\npresent in these images can adversely affect the accuracy of the\nmicrostructural measurements. In this context, we suggest a straightforward\ndenoising technique that can be applied to any DWI dataset as long as a\nlow-noise, single-subject dataset is obtained using the same DWI sequence.</p>\n<p>We created a simple 1D-CNN model with five layers, based on the 1D CNN for\ndenoising speech. The model consists of two convolutional layers followed by\nmax-pooling layers, and a dense layer. The first convolutional layer has\n16 one-dimensional filters of size 16, and the second layer has 32 filters of\nsize 8. ReLu activation function is applied to both convolutional layers.\nThe max-pooling layer has a kernel size of 2 and a stride of 2.\nThe dense layer maps the features extracted from the noisy image to the\nlow-noise reference image.</p>\n<section id=\"reference\">\n<h4>Reference<a class=\"headerlink\" href=\"#reference\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>Cheng H, Vinci-Booher S, Wang J, Caron B, Wen Q, Newman S, et al.\n(2022) Denoising diffusion weighted imaging data using convolutional neural\nnetworks.\nPLoS ONE 17(9): e0274396. <a class=\"reference external\" href=\"https://doi.org/10.1371/journal.pone.0274396\">https://doi.org/10.1371/journal.pone.0274396</a></p>\n</section>\n</section>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\" title=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser</span></code></a>(sig_length[,\u00a0optimizer,\u00a0loss,\u00a0...])</p></td>\n<td><p></p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.evac\">\n<span id=\"module-nn-evac\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.evac</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.evac\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Class and helper functions for fitting the EVAC+ model.</p>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.Block\" title=\"dipy.nn.evac.Block\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Block</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.ChannelSum\" title=\"dipy.nn.evac.ChannelSum\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">ChannelSum</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus\" title=\"dipy.nn.evac.EVACPlus\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">EVACPlus</span></code></a>([verbose])</p></td>\n<td><p>This class is intended for the EVAC+ model.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.logger\" title=\"dipy.nn.evac.logger\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">logger</span></code></a></p></td>\n<td><p>Instances of the Logger class represent a single logging channel.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.prepare_img\" title=\"dipy.nn.evac.prepare_img\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">prepare_img</span></code></a>(image)</p></td>\n<td><p>Function to prepare image for model input Specific to EVAC+</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.evac.init_model\" title=\"dipy.nn.evac.init_model\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">init_model</span></code></a>([model_scale])</p></td>\n<td><p>Function to create model for EVAC+</p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.histo_resdnn\">\n<span id=\"module-nn-histo-resdnn\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.histo_resdnn</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.histo_resdnn\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Class and helper functions for fitting the Histological ResDNN model.</p>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"dipy.nn.histo_resdnn.HistoResDNN\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a>([sh_order,\u00a0basis_type,\u00a0verbose])</p></td>\n<td><p>This class is intended for the ResDNN Histology Network model.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.logger\" title=\"dipy.nn.histo_resdnn.logger\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">logger</span></code></a></p></td>\n<td><p>Instances of the Logger class represent a single logging channel.</p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.model\">\n<span id=\"module-nn-model\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.model</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.model\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"dipy.nn.model.SingleLayerPerceptron\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a>([input_shape,\u00a0...])</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"dipy.nn.model.MultipleLayerPercepton\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a>([input_shape,\u00a0...])</p></td>\n<td><p></p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.synb0\">\n<span id=\"module-nn-synb0\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.synb0</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.synb0\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<p>Class and helper functions for fitting the Synb0 model.</p>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#id0\" title=\"dipy.nn.synb0.EncoderBlock\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#id69\" title=\"dipy.nn.synb0.DecoderBlock\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#id0\" title=\"dipy.nn.synb0.EncoderBlock\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#id69\" title=\"dipy.nn.synb0.DecoderBlock\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a>(*args,\u00a0**kwargs)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0\" title=\"dipy.nn.synb0.Synb0\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">Synb0</span></code></a>([verbose])</p></td>\n<td><p>This class is intended for the Synb0 model.</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.synb0.logger\" title=\"dipy.nn.synb0.logger\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">logger</span></code></a></p></td>\n<td><p>Instances of the Logger class represent a single logging channel.</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#id90\" title=\"dipy.nn.synb0.UNet3D\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">UNet3D</span></code></a>(input_shape)</p></td>\n<td><p></p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.synb0.normalize\" title=\"dipy.nn.synb0.normalize\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">normalize</span></code></a>(image[,\u00a0min_v,\u00a0max_v,\u00a0new_min,\u00a0...])</p></td>\n<td><p>normalization function</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.synb0.unnormalize\" title=\"dipy.nn.synb0.unnormalize\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">unnormalize</span></code></a>(image,\u00a0norm_min,\u00a0norm_max,\u00a0...)</p></td>\n<td><p>unnormalization function</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#id90\" title=\"dipy.nn.synb0.UNet3D\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">UNet3D</span></code></a>(input_shape)</p></td>\n<td><p></p></td>\n</tr>\n</tbody>\n</table>\n</section>\n<section id=\"module-dipy.nn.utils\">\n<span id=\"module-nn-utils\"></span><h2>Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.utils</span></code><a class=\"headerlink\" href=\"#module-dipy.nn.utils\" title=\"Permalink to this heading\">\u00b6</a></h2>\n<table class=\"autosummary longtable docutils align-default\">\n<tbody>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.utils.normalize\" title=\"dipy.nn.utils.normalize\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">normalize</span></code></a>(image[,\u00a0min_v,\u00a0max_v,\u00a0new_min,\u00a0...])</p></td>\n<td><p>normalization function</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.utils.unnormalize\" title=\"dipy.nn.utils.unnormalize\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">unnormalize</span></code></a>(image,\u00a0norm_min,\u00a0norm_max,\u00a0...)</p></td>\n<td><p>unnormalization function</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.utils.set_logger_level\" title=\"dipy.nn.utils.set_logger_level\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">set_logger_level</span></code></a>(log_level,\u00a0logger)</p></td>\n<td><p>Change the logger to one of the following: DEBUG, INFO, WARNING, CRITICAL, ERROR</p></td>\n</tr>\n<tr class=\"row-even\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.utils.transform_img\" title=\"dipy.nn.utils.transform_img\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">transform_img</span></code></a>(image,\u00a0affine[,\u00a0init_shape,\u00a0scale])</p></td>\n<td><p>Function to reshape image as an input to the model</p></td>\n</tr>\n<tr class=\"row-odd\"><td><p><a class=\"reference internal\" href=\"#dipy.nn.utils.recover_img\" title=\"dipy.nn.utils.recover_img\"><code class=\"xref py py-obj docutils literal notranslate\"><span class=\"pre\">recover_img</span></code></a>(image,\u00a0affine,\u00a0ori_shape[,\u00a0scale])</p></td>\n<td><p>Function to recover image back to its original shape</p></td>\n</tr>\n</tbody>\n</table>\n<section id=\"cnn1ddenoiser\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\" title=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser</span></code></a><a class=\"headerlink\" href=\"#cnn1ddenoiser\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.cnn_1d_denoising.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Cnn1DDenoiser</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sig_length</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'mean_squared_error'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">('accuracy',)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss_weights</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sig_length</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'mean_squared_error'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">('accuracy',)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss_weights</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Initialize the CNN 1D denoiser with the given parameters.</p>\n<section id=\"parameters\">\n<h4>Parameters<a class=\"headerlink\" href=\"#parameters\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>sig_length<span class=\"classifier\">int</span></dt><dd><p>Length of the DWI signal.</p>\n</dd>\n<dt>optimizer<span class=\"classifier\">str, optional</span></dt><dd><p>Name of the optimization algorithm to use. Options: \u2018adam\u2019, \u2018sgd\u2019,\n\u2018rmsprop\u2019, \u2018adagrad\u2019, \u2018adadelta\u2019.</p>\n</dd>\n<dt>loss<span class=\"classifier\">str, optional</span></dt><dd><p>Name of the loss function to use. Available options are\n\u2018mean_squared_error\u2019, \u2018mean_absolute_error\u2019,\n\u2018mean_absolute_percentage_error\u2019, \u2018mean_squared_logarithmic_error\u2019,\n\u2018squared_hinge\u2019, \u2018hinge\u2019, \u2018categorical_hinge\u2019, \u2018logcosh\u2019,\n\u2018categorical_crossentropy\u2019, \u2018sparse_categorical_crossentropy\u2019,\n\u2018binary_crossentropy\u2019, \u2018kullback_leibler_divergence\u2019, \u2018poisson\u2019,\n\u2018cosine_similarity\u2019.\nSuggested to go with \u2018mean_squared_error\u2019.</p>\n</dd>\n<dt>metrics<span class=\"classifier\">tuple of str or function, optional</span></dt><dd><p>List of metrics to be evaluated by the model during training and\ntesting. Available options are \u2018accuracy\u2019, \u2018binary_accuracy\u2019,\n\u2018categorical_accuracy\u2019, \u2018top_k_categorical_accuracy\u2019,\n\u2018sparse_categorical_accuracy\u2019, \u2018sparse_top_k_categorical_accuracy\u2019,\nand any custom function.</p>\n</dd>\n<dt>loss_weights<span class=\"classifier\">float or dict, optional</span></dt><dd><p>Scalar coefficients to weight the loss contributions of different\nmodel outputs. Can be a single float value or a dictionary mapping\noutput names to scalar coefficients.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.compile\">\n<span class=\"sig-name descname\"><span class=\"pre\">compile</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">metrics</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss_weights</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.compile\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Configure the model for training.</p>\n<section id=\"id1\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id1\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>optimizer<span class=\"classifier\">str or optimizer object, optional</span></dt><dd><p>Name of optimizer or optimizer object.</p>\n</dd>\n<dt>loss<span class=\"classifier\">str or objective function, optional</span></dt><dd><p>Name of objective function or objective function itself.\nIf \u2018None\u2019, the model will be compiled without any loss function\nand can only be used to predict output.</p>\n</dd>\n<dt>metrics<span class=\"classifier\">list of metrics, optional</span></dt><dd><p>List of metrics to be evaluated by the model during training\nand testing.</p>\n</dd>\n<dt>loss_weights<span class=\"classifier\">list or dict, optional</span></dt><dd><p>Optional list or dictionary specifying scalar coefficients(floats)\nto weight the loss contributions of different model outputs.\nThe loss value that will be minimized by the model will then be\nthe weighted sum of all individual losses. If a list, it is\nexpected to have a 1:1 mapping to the model\u2019s outputs. If a dict,\nit is expected to map output names (strings) to scalar\ncoefficients.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_dict</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluate the model on a test dataset.</p>\n<section id=\"id2\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id2\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x<span class=\"classifier\">ndarray</span></dt><dd><p>Test dataset (high-noise data). If 4D, it will be converted to 1D.</p>\n</dd>\n<dt>y<span class=\"classifier\">ndarray</span></dt><dd><p>Labels of the test dataset (low-noise data). If 4D, it will be\nconverted to 1D.</p>\n</dd>\n<dt>batch_size<span class=\"classifier\">int, optional</span></dt><dd><p>Number of samples per gradient update.</p>\n</dd>\n<dt>verbose<span class=\"classifier\">int, optional</span></dt><dd><p>Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line\nper epoch.</p>\n</dd>\n<dt>steps<span class=\"classifier\">int, optional</span></dt><dd><p>Total number of steps (batches of samples) before declaring the\nevaluation round finished.</p>\n</dd>\n<dt>callbacks<span class=\"classifier\">list, optional</span></dt><dd><p>List of callbacks to apply during evaluation.</p>\n</dd>\n<dt>max_queue_size<span class=\"classifier\">int, optional</span></dt><dd><p>Maximum size for the generator queue.</p>\n</dd>\n<dt>workers<span class=\"classifier\">int, optional</span></dt><dd><p>Maximum number of processes to spin up when using process-based\nthreading.</p>\n</dd>\n<dt>use_multiprocessing<span class=\"classifier\">bool, optional</span></dt><dd><p>If <cite>True</cite>, use process-based threading.</p>\n</dd>\n<dt>return_dict<span class=\"classifier\">bool, optional</span></dt><dd><p>If <cite>True</cite>, loss and metric results are returned as a dictionary.</p>\n</dd>\n</dl>\n</section>\n<section id=\"returns\">\n<h4>Returns<a class=\"headerlink\" href=\"#returns\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>List or dict</dt><dd><p>If <cite>return_dict</cite> is <cite>False</cite>, returns a list of [loss, metrics]\nvalues on the test dataset. If <cite>return_dict</cite> is <cite>True</cite>, returns\na dictionary of metric names and their corresponding values.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_split</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_data</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shuffle</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">initial_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps_per_epoch</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">validation_freq</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Train the model on train dataset.</p>\n<p>The fit method will train the model for a fixed number of epochs\n(iterations) on a dataset. If given data is  4D it will convert\nit into 1D.</p>\n<section id=\"id3\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id3\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x<span class=\"classifier\">ndarray</span></dt><dd><p>The input data, as an ndarray.</p>\n</dd>\n<dt>y<span class=\"classifier\">ndarray</span></dt><dd><p>The target data, as an ndarray.</p>\n</dd>\n<dt>batch_size<span class=\"classifier\">int or None, optional</span></dt><dd><p>Number of samples per batch of computation.</p>\n</dd>\n<dt>epochs<span class=\"classifier\">int, optional</span></dt><dd><p>The number of epochs.</p>\n</dd>\n<dt>verbose<span class=\"classifier\">\u2018auto\u2019, 0, 1, or 2, optional</span></dt><dd><p>Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line\nper epoch.</p>\n</dd>\n<dt>callbacks<span class=\"classifier\">list of keras.callbacks.Callback instances, optional</span></dt><dd><p>List of callbacks to apply during training.</p>\n</dd>\n<dt>validation_split<span class=\"classifier\">float between 0 and 1, optional</span></dt><dd><p>Fraction of the training data to be used as validation data.</p>\n</dd>\n<dt>validation_data<span class=\"classifier\">tuple (x_val, y_val) or None, optional</span></dt><dd><p>Data on which to evaluate the loss and any model metrics at\nthe end of each epoch.</p>\n</dd>\n<dt>shuffle<span class=\"classifier\">boolean, optional</span></dt><dd><p>This argument is ignored when x is a generator or an object of\ntf.data.Dataset.</p>\n</dd>\n<dt>initial_epoch<span class=\"classifier\">int, optional</span></dt><dd><p>Epoch at which to start training.</p>\n</dd>\n<dt>steps_per_epoch<span class=\"classifier\">int or None, optional</span></dt><dd><p>Total number of steps (batches of samples) before declaring one\nepoch finished and starting the next epoch.</p>\n</dd>\n<dt>validation_batch_size<span class=\"classifier\">int or None, optional</span></dt><dd><p>Number of samples per validation batch.</p>\n</dd>\n<dt>validation_steps<span class=\"classifier\">int or None, optional</span></dt><dd><p>Only relevant if validation_data is provided and is a\ntf.data dataset.</p>\n</dd>\n<dt>validation_freq<span class=\"classifier\">int or list/tuple/set, optional</span></dt><dd><p>Only relevant if validation data is provided. If an integer,\nspecifies how many training epochs to run before a new validation\nrun is performed. If a list, tuple, or set, specifies the epochs\non which to run validation.</p>\n</dd>\n<dt>max_queue_size<span class=\"classifier\">int, optional</span></dt><dd><p>Used for generator or keras.utils.Sequence input only.</p>\n</dd>\n<dt>workers<span class=\"classifier\">integer, optional</span></dt><dd><p>Used for generator or keras.utils.Sequence input only.</p>\n</dd>\n<dt>use_multiprocessing<span class=\"classifier\">boolean, optional</span></dt><dd><p>Used for generator or keras.utils.Sequence input only.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id4\">\n<h4>Returns<a class=\"headerlink\" href=\"#id4\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>hist<span class=\"classifier\">object</span></dt><dd><p>A History object. Its History.history attribute is a record of\ntraining loss values and metrics values at successive epochs.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.load_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">filepath</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.load_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the model weights from the specified file path.</p>\n<section id=\"id5\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id5\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>filepath<span class=\"classifier\">str</span></dt><dd><p>The file path from which to load the weights.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">steps</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">callbacks</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_queue_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">workers</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">use_multiprocessing</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Generate predictions for input samples.</p>\n<section id=\"id6\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id6\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x<span class=\"classifier\">ndarray</span></dt><dd><p>Input samples.</p>\n</dd>\n<dt>batch_size<span class=\"classifier\">int, optional</span></dt><dd><p>Number of samples per batch.</p>\n</dd>\n<dt>verbose<span class=\"classifier\">int, optional</span></dt><dd><p>Verbosity mode.</p>\n</dd>\n<dt>steps<span class=\"classifier\">int, optional</span></dt><dd><p>Total number of steps (batches of samples) before declaring the\nprediction round finished.</p>\n</dd>\n<dt>callbacks<span class=\"classifier\">list, optional</span></dt><dd><p>List of Keras callbacks to apply during prediction.</p>\n</dd>\n<dt>max_queue_size<span class=\"classifier\">int, optional</span></dt><dd><p>Maximum size for the generator queue.</p>\n</dd>\n<dt>workers<span class=\"classifier\">int, optional</span></dt><dd><p>Maximum number of processes to spin up when using process-based\nthreading.</p>\n</dd>\n<dt>use_multiprocessing<span class=\"classifier\">bool, optional</span></dt><dd><p>If <cite>True</cite>, use process-based threading. If <cite>False</cite>, use\nthread-based threading.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id7\">\n<h4>Returns<a class=\"headerlink\" href=\"#id7\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>ndarray</dt><dd><p>Numpy array of predictions.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.save_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">save_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">filepath</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">overwrite</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.save_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Save the weights of the model to HDF5 file format.</p>\n<section id=\"id8\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id8\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>filepath<span class=\"classifier\">str</span></dt><dd><p>The path where the weights should be saved.</p>\n</dd>\n<dt>overwrite<span class=\"classifier\">bool,optional</span></dt><dd><p>If <cite>True</cite>, overwrites the file if it already exists. If <cite>False</cite>,\nraises an error if the file already exists.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get the summary of the model.</p>\n<p>The summary is textual and includes information about:\nThe layers and their order in the model.\nThe output shape of each layer.</p>\n<section id=\"id9\">\n<h4>Returns<a class=\"headerlink\" href=\"#id9\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>summary<span class=\"classifier\">NoneType</span></dt><dd><p>the summary of the model</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.train_test_split\">\n<span class=\"sig-name descname\"><span class=\"pre\">train_test_split</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">test_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">train_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">random_state</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">shuffle</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">stratify</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.train_test_split\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Split the input data into random train and test subsets.</p>\n<section id=\"id10\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id10\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x: numpy array</dt><dd><p>input data.</p>\n</dd>\n<dt>y: numpy array</dt><dd><p>target data.</p>\n</dd>\n<dt>test_size: float or int, optional</dt><dd><p>If float, should be between 0.0 and 1.0 and represent the\nproportion of the dataset to include in the test split.\nIf int, represents the absolute number of test samples.\nIf None, the value is set to the complement of the train size.\nIf train_size is also None, it will be set to 0.25.</p>\n</dd>\n<dt>train_size: float or int, optional</dt><dd><p>If float, should be between 0.0 and 1.0 and represent the\nproportion of the dataset to include in the train split.\nIf int, represents the absolute number of train samples.\nIf None, the value is automatically set to the complement of the\ntest size.</p>\n</dd>\n<dt>random_state: int, RandomState instance or None, optional</dt><dd><p>Controls the shuffling applied to the data before applying\nthe split. Pass an int for reproducible output across multiple\nfunction calls. See Glossary.</p>\n</dd>\n<dt>shuffle: bool, optional</dt><dd><p>Whether or not to shuffle the data before splitting.\nIf shuffle=False then stratify must be None.</p>\n</dd>\n<dt>stratify: array-like, optional</dt><dd><p>If not None, data is split in a stratified fashion,\nusing this as the class labels. Read more in the User Guide.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id11\">\n<h4>Returns<a class=\"headerlink\" href=\"#id11\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>Tuple of four numpy arrays: x_train, x_test, y_train, y_test.</p>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"block\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.evac.Block\" title=\"dipy.nn.evac.Block\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Block</span></code></a><a class=\"headerlink\" href=\"#block\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.Block\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Block</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.Block\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.Block.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">out_channels</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_size</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">strides</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">padding</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">drop_r</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">n_layers</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">layer_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'down'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.Block.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.Block.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">passed</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.Block.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id12\"><span class=\"problematic\" id=\"id13\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id14\"><span class=\"problematic\" id=\"id15\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"channelsum\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.evac.ChannelSum\" title=\"dipy.nn.evac.ChannelSum\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ChannelSum</span></code></a><a class=\"headerlink\" href=\"#channelsum\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.ChannelSum\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">ChannelSum</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.ChannelSum\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.ChannelSum.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.ChannelSum.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.ChannelSum.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">inputs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.ChannelSum.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id16\"><span class=\"problematic\" id=\"id17\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id18\"><span class=\"problematic\" id=\"id19\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"evacplus\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus\" title=\"dipy.nn.evac.EVACPlus\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EVACPlus</span></code></a><a class=\"headerlink\" href=\"#evacplus\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.EVACPlus\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">EVACPlus</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.EVACPlus\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p>This class is intended for the EVAC+ model.</p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.EVACPlus.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.EVACPlus.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The model was pre-trained for usage on\nbrain extraction of T1 images.</p>\n<p>This model is designed to take as input\na T1 weighted image.</p>\n<section id=\"id20\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id20\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>verbose<span class=\"classifier\">bool (optional)</span></dt><dd><p>Whether to show information about the processing.\nDefault: False</p>\n</dd>\n</dl>\n</section>\n<section id=\"references\">\n<h4>References<a class=\"headerlink\" href=\"#references\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<aside class=\"footnote-list brackets\">\n<aside class=\"footnote brackets\" id=\"id21\" role=\"note\">\n<span class=\"label\"><span class=\"fn-bracket\">[</span>1<span class=\"fn-bracket\">]</span></span>\n<p>Park, J.S., Fadnavis, S., &amp; Garyfallidis, E. (2022).\nEVAC+: Multi-scale V-net with Deep Feature\nCRF Layers for Brain Extraction.</p>\n</aside>\n</aside>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.EVACPlus.fetch_default_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">fetch_default_weights</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.EVACPlus.fetch_default_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the model pre-training weights to use for the fitting.\nWhile the user can load different weights, the function\nis mainly intended for the class function \u2018predict\u2019.</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.EVACPlus.load_model_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_model_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">weights_path</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.EVACPlus.load_model_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the custom pre-training weights to use for the fitting.</p>\n<section id=\"id22\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id22\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>weights_path<span class=\"classifier\">str</span></dt><dd><p>Path to the file containing the weights (hdf5, saved by tensorflow)</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.EVACPlus.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">T1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">affine</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">voxsize</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(1,</span> <span class=\"pre\">1,</span> <span class=\"pre\">1)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_affine</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">return_prob</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.EVACPlus.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Wrapper function to facilitate prediction of larger dataset.</p>\n<section id=\"id23\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id23\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>T1<span class=\"classifier\">np.ndarray or list of np.ndarrys</span></dt><dd><p>For a single image, input should be a 3D array.\nIf multiple images, it should be a 4D array or a list.</p>\n</dd>\n<dt>affine<span class=\"classifier\">np.ndarray (4, 4) or (batch, 4, 4)</span></dt><dd><p>or list of np.ndarrays with len of batch\nAffine matrix for the T1 image. Should have\nbatch dimension if T1 has one.</p>\n</dd>\n<dt>voxsize<span class=\"classifier\">np.ndarray or list or tuple, optional</span></dt><dd><p>(3,) or (batch, 3)\nvoxel size of the T1 image.\nDefault is (1, 1, 1)</p>\n</dd>\n<dt>batch_size<span class=\"classifier\">int, optional</span></dt><dd><p>Number of images per prediction pass. Only available if data\nis provided with a batch dimension.\nConsider lowering it if you get an out of memory error.\nIncrease it if you want it to be faster and have a lot of data.\nIf None, batch_size will be set to 1 if the provided image\nhas a batch dimension.\nDefault is None</p>\n</dd>\n<dt>return_affine<span class=\"classifier\">bool, optional</span></dt><dd><p>Whether to return the affine matrix. Useful if the input was a\nfile path.\nDefault is False</p>\n</dd>\n<dt>return_prob<span class=\"classifier\">bool, optional</span></dt><dd><p>Whether to return the probability map instead of a\nbinary mask. Useful for testing.\nDefault is False</p>\n</dd>\n</dl>\n</section>\n<section id=\"id24\">\n<h4>Returns<a class=\"headerlink\" href=\"#id24\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>pred_output<span class=\"classifier\">np.ndarray (\u2026) or (batch, \u2026)</span></dt><dd><p>Predicted brain mask</p>\n</dd>\n<dt>affine<span class=\"classifier\">np.ndarray (\u2026) or (batch, \u2026)</span></dt><dd><p>affine matrix of mask\nonly if return_affine is True</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"logger\">\n<h3>logger<a class=\"headerlink\" href=\"#logger\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.logger\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">logger</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.logger\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Instances of the Logger class represent a single logging channel. A\n\u201clogging channel\u201d indicates an area of an application. Exactly how an\n\u201carea\u201d is defined is up to the application developer. Since an\napplication can have any number of areas, logging channels are identified\nby a unique string. Application areas can be nested (e.g. an area\nof \u201cinput processing\u201d might include sub-areas \u201cread CSV files\u201d, \u201cread\nXLS files\u201d and \u201cread Gnumeric files\u201d). To cater for this natural nesting,\nchannel names are organized into a namespace hierarchy where levels are\nseparated by periods, much like the Java or Python package namespace. So\nin the instance given above, channel names might be \u201cinput\u201d for the upper\nlevel, and \u201cinput.csv\u201d, \u201cinput.xls\u201d and \u201cinput.gnu\u201d for the sub-levels.\nThere is no arbitrary limit to the depth of nesting.</p>\n</dd></dl>\n\n</section>\n<section id=\"prepare-img\">\n<h3>prepare_img<a class=\"headerlink\" href=\"#prepare-img\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.prepare_img\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">prepare_img</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.prepare_img\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Function to prepare image for model input\nSpecific to EVAC+</p>\n<section id=\"id25\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id25\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>image<span class=\"classifier\">np.ndarray</span></dt><dd><p>Input image</p>\n</dd>\n</dl>\n</section>\n<section id=\"id26\">\n<h4>Returns<a class=\"headerlink\" href=\"#id26\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>input_data : dict</p>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"init-model\">\n<h3>init_model<a class=\"headerlink\" href=\"#init-model\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.evac.init_model\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.evac.</span></span><span class=\"sig-name descname\"><span class=\"pre\">init_model</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">model_scale</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">16</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.evac.init_model\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Function to create model for EVAC+</p>\n<section id=\"id27\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id27\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>model_scale<span class=\"classifier\">int, optional</span></dt><dd><p>The scale of the model\nShould match the saved weights from fetcher\nDefault is 16</p>\n</dd>\n</dl>\n</section>\n<section id=\"id28\">\n<h4>Returns<a class=\"headerlink\" href=\"#id28\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>model : tf.keras.Model</p>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"historesdnn\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"dipy.nn.histo_resdnn.HistoResDNN\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a><a class=\"headerlink\" href=\"#historesdnn\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">HistoResDNN</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">8</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'tournier07'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p>This class is intended for the ResDNN Histology Network model.</p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">sh_order</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">8</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">basis_type</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'tournier07'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The model was re-trained for usage with a different basis function\n(\u2018tournier07\u2019) like the proposed model in [1, 2].</p>\n<p>To obtain the pre-trained model, use::\n&gt;&gt;&gt; resdnn_model = HistoResDNN()\n&gt;&gt;&gt; fetch_model_weights_path = get_fnames(\u2018histo_resdnn_weights\u2019)\n&gt;&gt;&gt; resdnn_model.load_model_weights(fetch_model_weights_path)</p>\n<p>This model is designed to take as input raw DWI signal on a sphere\n(ODF) represented as SH of order 8 in the tournier basis and predict\nfODF of order 8 in the tournier basis. Effectively, this model is\nmimicking a CSD fit.</p>\n<section id=\"id29\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id29\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>sh_order<span class=\"classifier\">int, optional</span></dt><dd><p>Maximum SH order in the SH fit.  For <code class=\"docutils literal notranslate\"><span class=\"pre\">sh_order</span></code>, there will be\n<code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> SH coefficients for a\nsymmetric basis. Default: 8</p>\n</dd>\n<dt>basis_type<span class=\"classifier\">{\u2018tournier07\u2019, \u2018descoteaux07\u2019}, optional</span></dt><dd><p><code class=\"docutils literal notranslate\"><span class=\"pre\">tournier07</span></code> (default) or <code class=\"docutils literal notranslate\"><span class=\"pre\">descoteaux07</span></code>.</p>\n</dd>\n<dt>verbose<span class=\"classifier\">bool (optional)</span></dt><dd><p>Whether to show information about the processing.\nDefault: False</p>\n</dd>\n</dl>\n</section>\n<section id=\"id30\">\n<h4>References<a class=\"headerlink\" href=\"#id30\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<aside class=\"footnote-list brackets\">\n<aside class=\"footnote brackets\" id=\"id31\" role=\"note\">\n<span class=\"label\"><span class=\"fn-bracket\">[</span>1<span class=\"fn-bracket\">]</span></span>\n<p>Nath, V., Schilling, K. G., Parvathaneni, P., Hansen,\nC. B., Hainline, A. E., Huo, Y., \u2026 &amp; Stepniewska, I. (2019).\nDeep learning reveals untapped information for local white-matter\nfiber reconstruction in diffusion-weighted MRI.\nMagnetic resonance imaging, 62, 220-227.</p>\n</aside>\n<aside class=\"footnote brackets\" id=\"id32\" role=\"note\">\n<span class=\"label\"><span class=\"fn-bracket\">[</span>2<span class=\"fn-bracket\">]</span></span>\n<p>Nath, V., Schilling, K. G., Hansen, C. B., Parvathaneni,\nP., Hainline, A. E., Bermudez, C., \u2026 &amp; St\u0119pniewska, I. (2019).\nDeep learning captures more accurate diffusion fiber orientations\ndistributions than constrained spherical deconvolution.\narXiv preprint arXiv:1911.07927.</p>\n</aside>\n</aside>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">fetch_default_weights</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the model pre-training weights to use for the fitting.\nWill not work if the declared SH_ORDER does not match the weights\nexpected input.</p>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_model_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">weights_path</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the custom pre-training weights to use for the fitting.\nWill not work if the declared SH_ORDER does not match the weights\nexpected input.</p>\n<dl class=\"simple\">\n<dt>The weights for a sh_order of 8 can be obtained via the function:</dt><dd><p>get_fnames(\u2018histo_resdnn_weights\u2019).</p>\n</dd>\n</dl>\n<section id=\"id33\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id33\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>weights_path<span class=\"classifier\">str</span></dt><dd><p>Path to the file containing the weights (hdf5, saved by tensorflow)</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.HistoResDNN.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">data</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">gtab</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">mask</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">chunk_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1000</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Wrapper function to facilitate prediction of larger dataset.\nThe function will mask, normalize, split, predict and \u2018re-assemble\u2019\nthe data as a volume.</p>\n<section id=\"id34\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id34\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>data<span class=\"classifier\">np.ndarray</span></dt><dd><p>DWI signal in a 4D array</p>\n</dd>\n<dt>gtab<span class=\"classifier\">GradientTable class instance</span></dt><dd><p>The acquisition scheme matching the data (must contain at least\none b0)</p>\n</dd>\n<dt>mask<span class=\"classifier\">np.ndarray (optional)</span></dt><dd><p>Binary mask of the brain to avoid unnecessary computation and\nunreliable prediction outside the brain.\nDefault: Compute prediction only for nonzero voxels (with at least\none nonzero DWI value).</p>\n</dd>\n</dl>\n</section>\n<section id=\"id35\">\n<h4>Returns<a class=\"headerlink\" href=\"#id35\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>pred_sh_coef<span class=\"classifier\">np.ndarray (x, y, z, M)</span></dt><dd><p>Predicted fODF (as SH). The volume has matching shape to the input\ndata, but with <code class=\"docutils literal notranslate\"><span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">1)</span> <span class=\"pre\">*</span> <span class=\"pre\">(sh_order</span> <span class=\"pre\">+</span> <span class=\"pre\">2)</span> <span class=\"pre\">/</span> <span class=\"pre\">2</span></code> as a last\ndimension.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id36\">\n<h3>logger<a class=\"headerlink\" href=\"#id36\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.histo_resdnn.logger\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.histo_resdnn.</span></span><span class=\"sig-name descname\"><span class=\"pre\">logger</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.histo_resdnn.logger\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Instances of the Logger class represent a single logging channel. A\n\u201clogging channel\u201d indicates an area of an application. Exactly how an\n\u201carea\u201d is defined is up to the application developer. Since an\napplication can have any number of areas, logging channels are identified\nby a unique string. Application areas can be nested (e.g. an area\nof \u201cinput processing\u201d might include sub-areas \u201cread CSV files\u201d, \u201cread\nXLS files\u201d and \u201cread Gnumeric files\u201d). To cater for this natural nesting,\nchannel names are organized into a namespace hierarchy where levels are\nseparated by periods, much like the Java or Python package namespace. So\nin the instance given above, channel names might be \u201cinput\u201d for the upper\nlevel, and \u201cinput.csv\u201d, \u201cinput.xls\u201d and \u201cinput.gnu\u201d for the sub-levels.\nThere is no arbitrary limit to the depth of nesting.</p>\n</dd></dl>\n\n</section>\n<section id=\"singlelayerperceptron\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"dipy.nn.model.SingleLayerPerceptron\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a><a class=\"headerlink\" href=\"#singlelayerperceptron\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">SingleLayerPerceptron</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">128</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">128</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Single Layer Perceptron with Dropout.</p>\n<section id=\"id37\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id37\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>input_shape<span class=\"classifier\">tuple</span></dt><dd><p>Shape of data to be trained</p>\n</dd>\n<dt>num_hidden<span class=\"classifier\">int</span></dt><dd><p>Number of nodes in hidden layer</p>\n</dd>\n<dt>act_hidden<span class=\"classifier\">string</span></dt><dd><p>Activation function used in hidden layer</p>\n</dd>\n<dt>dropout<span class=\"classifier\">float</span></dt><dd><p>Dropout ratio</p>\n</dd>\n<dt>num_out<span class=\"classifier\">10</span></dt><dd><p>Number of nodes in output layer</p>\n</dd>\n<dt>act_out<span class=\"classifier\">string</span></dt><dd><p>Activation function used in output layer</p>\n</dd>\n<dt>optimizer<span class=\"classifier\">string</span></dt><dd><p>Select optimizer. Default adam.</p>\n</dd>\n<dt>loss<span class=\"classifier\">string</span></dt><dd><p>Select loss function for measuring accuracy.\nDefault sparse_categorical_crossentropy.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluate the model on test dataset.</p>\n<p>The evaluate method will evaluate the model on a test\ndataset.</p>\n<section id=\"id38\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id38\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_test<span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset</p>\n</dd>\n<dt>y_test<span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_test is the labels of the test dataset</p>\n</dd>\n<dt>verbose<span class=\"classifier\">int (Default = 2)</span></dt><dd><p>By setting verbose 0, 1 or 2 you just say how do you want to\n\u2018see\u2019 the training progress for each epoch.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id39\">\n<h4>Returns<a class=\"headerlink\" href=\"#id39\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>evaluate<span class=\"classifier\">List</span></dt><dd><p>return list of loss value and accuracy value on test dataset</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">5</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Train the model on train dataset.</p>\n<p>The fit method will train the model for a fixed\nnumber of epochs (iterations) on a dataset.</p>\n<section id=\"id40\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id40\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_train<span class=\"classifier\">ndarray</span></dt><dd><p>the x_train is the train dataset</p>\n</dd>\n<dt>y_train<span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_train is the labels of the train dataset</p>\n</dd>\n<dt>epochs<span class=\"classifier\">int (Default = 5)</span></dt><dd><p>the number of epochs</p>\n</dd>\n</dl>\n</section>\n<section id=\"id41\">\n<h4>Returns<a class=\"headerlink\" href=\"#id41\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>hist<span class=\"classifier\">object</span></dt><dd><p>A History object. Its History.history attribute is a record of\ntraining loss values and metrics values at successive epochs</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Predict the output from input samples.</p>\n<p>The predict method will generates output predictions\nfor the input samples.</p>\n<section id=\"id42\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id42\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_train<span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset or input samples</p>\n</dd>\n</dl>\n</section>\n<section id=\"id43\">\n<h4>Returns<a class=\"headerlink\" href=\"#id43\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>predict<span class=\"classifier\">ndarray shape(TestSize,OutputSize)</span></dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.SingleLayerPerceptron.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.SingleLayerPerceptron.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get the summary of the model.</p>\n<p>The summary is textual and includes information about:\nThe layers and their order in the model.\nThe output shape of each layer.</p>\n<section id=\"id44\">\n<h4>Returns<a class=\"headerlink\" href=\"#id44\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>summary<span class=\"classifier\">NoneType</span></dt><dd><p>the summary of the model</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"multiplelayerpercepton\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"dipy.nn.model.MultipleLayerPercepton\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a><a class=\"headerlink\" href=\"#multiplelayerpercepton\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.model.</span></span><span class=\"sig-name descname\"><span class=\"pre\">MultipleLayerPercepton</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(128,)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(28,</span> <span class=\"pre\">28)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(128,)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_hidden</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'relu'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">dropout</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">0.2</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">num_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">10</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">act_out</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'softmax'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">loss</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'sparse_categorical_crossentropy'</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">optimizer</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">'adam'</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Multiple Layer Perceptron with Dropout.</p>\n<section id=\"id45\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id45\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>input_shape<span class=\"classifier\">tuple</span></dt><dd><p>Shape of data to be trained</p>\n</dd>\n<dt>num_hidden<span class=\"classifier\">array-like</span></dt><dd><p>List of number of nodes in hidden layers</p>\n</dd>\n<dt>act_hidden<span class=\"classifier\">string</span></dt><dd><p>Activation function used in hidden layer</p>\n</dd>\n<dt>dropout<span class=\"classifier\">float</span></dt><dd><p>Dropout ratio</p>\n</dd>\n<dt>num_out<span class=\"classifier\">10</span></dt><dd><p>Number of nodes in output layer</p>\n</dd>\n<dt>act_out<span class=\"classifier\">string</span></dt><dd><p>Activation function used in output layer</p>\n</dd>\n<dt>optimizer<span class=\"classifier\">string</span></dt><dd><p>Select optimizer. Default adam.</p>\n</dd>\n<dt>loss<span class=\"classifier\">string</span></dt><dd><p>Select loss function for measuring accuracy.\nDefault sparse_categorical_crossentropy.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.evaluate\">\n<span class=\"sig-name descname\"><span class=\"pre\">evaluate</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_test</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.evaluate\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Evaluate the model on test dataset.</p>\n<p>The evaluate method will evaluate the model on a test\ndataset.</p>\n<section id=\"id46\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id46\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_test<span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset</p>\n</dd>\n<dt>y_test<span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_test is the labels of the test dataset</p>\n</dd>\n<dt>verbose<span class=\"classifier\">int (Default = 2)</span></dt><dd><p>By setting verbose 0, 1 or 2 you just say how do you want to\n\u2018see\u2019 the training progress for each epoch.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id47\">\n<h4>Returns<a class=\"headerlink\" href=\"#id47\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>evaluate<span class=\"classifier\">List</span></dt><dd><p>return list of loss value and accuracy value on test dataset</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.fit\">\n<span class=\"sig-name descname\"><span class=\"pre\">fit</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">y_train</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">epochs</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">5</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.fit\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Train the model on train dataset.</p>\n<p>The fit method will train the model for a fixed\nnumber of epochs (iterations) on a dataset.</p>\n<section id=\"id48\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id48\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_train<span class=\"classifier\">ndarray</span></dt><dd><p>the x_train is the train dataset</p>\n</dd>\n<dt>y_train<span class=\"classifier\">ndarray shape=(BatchSize,)</span></dt><dd><p>the y_train is the labels of the train dataset</p>\n</dd>\n<dt>epochs<span class=\"classifier\">int (Default = 5)</span></dt><dd><p>the number of epochs</p>\n</dd>\n</dl>\n</section>\n<section id=\"id49\">\n<h4>Returns<a class=\"headerlink\" href=\"#id49\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>hist<span class=\"classifier\">object</span></dt><dd><p>A History object. Its History.history attribute is a record of\ntraining loss values and metrics values at successive epochs</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">x_test</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Predict the output from input samples.</p>\n<p>The predict method will generates output predictions\nfor the input samples.</p>\n<section id=\"id50\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id50\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>x_train<span class=\"classifier\">ndarray</span></dt><dd><p>the x_test is the test dataset or input samples</p>\n</dd>\n</dl>\n</section>\n<section id=\"id51\">\n<h4>Returns<a class=\"headerlink\" href=\"#id51\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>predict<span class=\"classifier\">ndarray shape(TestSize,OutputSize)</span></dt><dd><p>Numpy array(s) of predictions.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.model.MultipleLayerPercepton.summary\">\n<span class=\"sig-name descname\"><span class=\"pre\">summary</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.model.MultipleLayerPercepton.summary\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Get the summary of the model.</p>\n<p>The summary is textual and includes information about:\nThe layers and their order in the model.\nThe output shape of each layer.</p>\n<section id=\"id52\">\n<h4>Returns<a class=\"headerlink\" href=\"#id52\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>summary<span class=\"classifier\">NoneType</span></dt><dd><p>the summary of the model</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"encoderblock\">\n<h3><a class=\"reference internal\" href=\"#id0\" title=\"dipy.nn.synb0.EncoderBlock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><a class=\"headerlink\" href=\"#encoderblock\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.EncoderBlock\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">EncoderBlock</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.EncoderBlock\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.EncoderBlock.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">out_channels</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_size</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">strides</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">padding</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.EncoderBlock.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.EncoderBlock.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.EncoderBlock.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id53\"><span class=\"problematic\" id=\"id54\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id55\"><span class=\"problematic\" id=\"id56\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"decoderblock\">\n<h3><a class=\"reference internal\" href=\"#id69\" title=\"dipy.nn.synb0.DecoderBlock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><a class=\"headerlink\" href=\"#decoderblock\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.DecoderBlock\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">DecoderBlock</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.DecoderBlock\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.DecoderBlock.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">out_channels</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_size</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">strides</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">padding</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.DecoderBlock.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.DecoderBlock.call\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.DecoderBlock.call\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id57\"><span class=\"problematic\" id=\"id58\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id59\"><span class=\"problematic\" id=\"id60\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id61\">\n<h3><a class=\"reference internal\" href=\"#id0\" title=\"dipy.nn.synb0.EncoderBlock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><a class=\"headerlink\" href=\"#id61\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"id0\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">EncoderBlock</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id0\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"id62\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">out_channels</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_size</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">strides</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">padding</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id62\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"id63\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id63\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id64\"><span class=\"problematic\" id=\"id65\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id66\"><span class=\"problematic\" id=\"id67\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id68\">\n<h3><a class=\"reference internal\" href=\"#id69\" title=\"dipy.nn.synb0.DecoderBlock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><a class=\"headerlink\" href=\"#id68\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"id69\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">DecoderBlock</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">*</span></span><span class=\"n\"><span class=\"pre\">args</span></span></em>, <em class=\"sig-param\"><span class=\"o\"><span class=\"pre\">**</span></span><span class=\"n\"><span class=\"pre\">kwargs</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id69\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Layer</span></code></p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"id70\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">out_channels</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">kernel_size</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">strides</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">padding</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id70\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"id71\">\n<span class=\"sig-name descname\"><span class=\"pre\">call</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id71\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>This is where the layer\u2019s logic lives.</p>\n<p>The <cite>call()</cite> method may not create state (except in its first\ninvocation, wrapping the creation of variables or other resources in\n<cite>tf.init_scope()</cite>).  It is recommended to create state, including\n<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>\n<blockquote>\n<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>\n</div></blockquote>\n<p>called automatically before <cite>call()</cite> executes for the first time.</p>\n<dl>\n<dt>Args:</dt><dd><dl>\n<dt>inputs: Input tensor, or dict/list/tuple of input tensors.</dt><dd><p>The first positional <cite>inputs</cite> argument is subject to special rules:\n- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>\n<blockquote>\n<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value\nof a keyword argument.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as\ntensors.</p></li>\n<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>\n<li><p>Layers are built (<cite>build(input_shape)</cite> method)\nusing shape info from <cite>inputs</cite> only.</p></li>\n<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>\n<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.\nIf a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their\ncasting behavior in mixed precision should be handled manually.</p></li>\n<li><p>The SavedModel input specification is generated using <cite>inputs</cite>\nonly.</p></li>\n<li><p>Integration with various ecosystem packages like TFMOT, TFLite,\nTF.js, etc is only supported for <cite>inputs</cite> and not for tensors in\npositional and keyword arguments.</p></li>\n</ul>\n</dd>\n<dt><a href=\"#id72\"><span class=\"problematic\" id=\"id73\">*</span></a>args: Additional positional arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.</p>\n</dd>\n<dt><a href=\"#id74\"><span class=\"problematic\" id=\"id75\">**</span></a>kwargs: Additional keyword arguments. May contain tensors, although</dt><dd><p>this is not recommended, for the reasons above.\nThe following optional keyword arguments are reserved:\n- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>\n<blockquote>\n<div><p>whether the <cite>call</cite> is meant for training or inference.</p>\n</div></blockquote>\n<ul class=\"simple\">\n<li><p><cite>mask</cite>: Boolean input mask. If the layer\u2019s <cite>call()</cite> method takes a\n<cite>mask</cite> argument, its default value will be set to the mask\ngenerated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come\nfrom a layer that generated a corresponding mask, i.e. if it came\nfrom a Keras layer with masking support).</p></li>\n</ul>\n</dd>\n</dl>\n</dd>\n<dt>Returns:</dt><dd><p>A tensor or list/tuple of tensors.</p>\n</dd>\n</dl>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"synb0\">\n<h3><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0\" title=\"dipy.nn.synb0.Synb0\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Synb0</span></code></a><a class=\"headerlink\" href=\"#synb0\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py class\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.Synb0\">\n<em class=\"property\"><span class=\"pre\">class</span><span class=\"w\"> </span></em><span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">Synb0</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.Synb0\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Bases: <a class=\"reference external\" href=\"https://docs.python.org/3/library/functions.html#object\" title=\"(in Python v3.11)\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">object</span></code></a></p>\n<p>This class is intended for the Synb0 model.\nThe model is the deep learning part of the Synb0-Disco\npipeline, thus stand-alone usage is not\nrecommended.</p>\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.Synb0.__init__\">\n<span class=\"sig-name descname\"><span class=\"pre\">__init__</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">verbose</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">False</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.Synb0.__init__\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>The model was pre-trained for usage on pre-processed images\nfollowing the synb0-disco pipeline.\nOne can load their own weights using load_model_weights.</p>\n<p>This model is designed to take as input\na b0 image and a T1 weighted image.</p>\n<p>It was designed to predict a b-inf image.</p>\n<section id=\"id76\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id76\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>verbose<span class=\"classifier\">bool (optional)</span></dt><dd><p>Whether to show information about the processing.\nDefault: False</p>\n</dd>\n</dl>\n</section>\n<section id=\"id77\">\n<h4>References<a class=\"headerlink\" href=\"#id77\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<aside class=\"footnote-list brackets\">\n<aside class=\"footnote brackets\" id=\"id78\" role=\"note\">\n<span class=\"label\"><span class=\"fn-bracket\">[</span>1<span class=\"fn-bracket\">]</span></span>\n<p>Schilling, K. G., Blaber, J., Huo, Y., Newton, A.,\nHansen, C., Nath, V., \u2026 &amp; Landman, B. A. (2019).\nSynthesized b0 for diffusion distortion correction (Synb0-DisCo).\nMagnetic resonance imaging, 64, 62-70.</p>\n</aside>\n<aside class=\"footnote brackets\" id=\"id79\" role=\"note\">\n<span class=\"label\"><span class=\"fn-bracket\">[</span>2<span class=\"fn-bracket\">]</span></span>\n<p>Schilling, K. G., Blaber, J., Hansen, C., Cai, L.,\nRogers, B., Anderson, A. W., \u2026 &amp; Landman, B. A. (2020).\nDistortion correction of diffusion weighted MRI without reverse\nphase-encoding scans or field-maps.\nPloS one, 15(7), e0236418.</p>\n</aside>\n</aside>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.Synb0.fetch_default_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">fetch_default_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">idx</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.Synb0.fetch_default_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the model pre-training weights to use for the fitting.\nWhile the user can load different weights, the function\nis mainly intended for the class function \u2018predict\u2019.</p>\n<section id=\"id80\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id80\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>idx<span class=\"classifier\">int</span></dt><dd><p>The idx of the default weights. It can be from 0~4.</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.Synb0.load_model_weights\">\n<span class=\"sig-name descname\"><span class=\"pre\">load_model_weights</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">weights_path</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.Synb0.load_model_weights\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Load the custom pre-training weights to use for the fitting.</p>\n<section id=\"id81\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id81\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>weights_path<span class=\"classifier\">str</span></dt><dd><p>Path to the file containing the weights (hdf5, saved by tensorflow)</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n<dl class=\"py method\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.Synb0.predict\">\n<span class=\"sig-name descname\"><span class=\"pre\">predict</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">b0</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">T1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">batch_size</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">average</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">True</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.Synb0.predict\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Wrapper function to facilitate prediction of larger dataset.\nThe function will pad the data to meet the required shape of image.\nNote that the b0 and T1 image should have the same shape</p>\n<section id=\"id82\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id82\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>b0<span class=\"classifier\">np.ndarray (batch, 77, 91, 77) or (77, 91, 77)</span></dt><dd><p>For a single image, input should be a 3D array. If multiple images,\nthere should also be a batch dimension.</p>\n</dd>\n<dt>T1<span class=\"classifier\">np.ndarray (batch, 77, 91, 77) or (77, 91, 77)</span></dt><dd><p>For a single image, input should be a 3D array. If multiple images,\nthere should also be a batch dimension.</p>\n</dd>\n<dt>batch_size<span class=\"classifier\">int</span></dt><dd><p>Number of images per prediction pass. Only available if data\nis provided with a batch dimension.\nConsider lowering it if you get an out of memory error.\nIncrease it if you want it to be faster and have a lot of data.\nIf None, batch_size will be set to 1 if the provided image\nhas a batch dimension.\nDefault is None</p>\n</dd>\n<dt>average<span class=\"classifier\">bool</span></dt><dd><p>Whether the function follows the Synb0-Disco pipeline and\naverages the prediction of 5 different models.\nIf False, it uses the loaded weights for prediction.\nDefault is True.</p>\n</dd>\n</dl>\n</section>\n<section id=\"id83\">\n<h4>Returns<a class=\"headerlink\" href=\"#id83\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>pred_output<span class=\"classifier\">np.ndarray (\u2026) or (batch, \u2026)</span></dt><dd><p>Reconstructed b-inf image(s)</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</dd></dl>\n\n</section>\n<section id=\"id84\">\n<h3>logger<a class=\"headerlink\" href=\"#id84\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.logger\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">logger</span></span><span class=\"sig-paren\">(</span><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.logger\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Instances of the Logger class represent a single logging channel. A\n\u201clogging channel\u201d indicates an area of an application. Exactly how an\n\u201carea\u201d is defined is up to the application developer. Since an\napplication can have any number of areas, logging channels are identified\nby a unique string. Application areas can be nested (e.g. an area\nof \u201cinput processing\u201d might include sub-areas \u201cread CSV files\u201d, \u201cread\nXLS files\u201d and \u201cread Gnumeric files\u201d). To cater for this natural nesting,\nchannel names are organized into a namespace hierarchy where levels are\nseparated by periods, much like the Java or Python package namespace. So\nin the instance given above, channel names might be \u201cinput\u201d for the upper\nlevel, and \u201cinput.csv\u201d, \u201cinput.xls\u201d and \u201cinput.gnu\u201d for the sub-levels.\nThere is no arbitrary limit to the depth of nesting.</p>\n</dd></dl>\n\n</section>\n<section id=\"unet3d\">\n<h3>UNet3D<a class=\"headerlink\" href=\"#unet3d\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.UNet3D\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">UNet3D</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.UNet3D\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n</section>\n<section id=\"normalize\">\n<h3>normalize<a class=\"headerlink\" href=\"#normalize\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.normalize\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">normalize</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">min_v</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_v</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">new_min</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">-1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">new_max</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.normalize\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>normalization function</p>\n<section id=\"id85\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id85\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>image : np.ndarray\nmin_v : int or float (optional)</p>\n<blockquote>\n<div><p>minimum value range for normalization\nintensities below min_v will be clipped\nif None it is set to min value of image\nDefault : None</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>max_v<span class=\"classifier\">int or float (optional)</span></dt><dd><p>maximum value range for normalization\nintensities above max_v will be clipped\nif None it is set to max value of image\nDefault : None</p>\n</dd>\n<dt>new_min<span class=\"classifier\">int or float (optional)</span></dt><dd><p>new minimum value after normalization\nDefault : 0</p>\n</dd>\n<dt>new_max<span class=\"classifier\">int or float (optional)</span></dt><dd><p>new maximum value after normalization\nDefault : 1</p>\n</dd>\n</dl>\n</section>\n<section id=\"id86\">\n<h4>Returns<a class=\"headerlink\" href=\"#id86\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>np.ndarray</dt><dd><p>Normalized image from range new_min to new_max</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"unnormalize\">\n<h3>unnormalize<a class=\"headerlink\" href=\"#unnormalize\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.synb0.unnormalize\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">unnormalize</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">norm_min</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">norm_max</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">min_v</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_v</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.synb0.unnormalize\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>unnormalization function</p>\n<section id=\"id87\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id87\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>image : np.ndarray\nnorm_min : int or float</p>\n<blockquote>\n<div><p>minimum value of normalized image</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>norm_max<span class=\"classifier\">int or float</span></dt><dd><p>maximum value of normalized image</p>\n</dd>\n<dt>min_v<span class=\"classifier\">int or float</span></dt><dd><p>minimum value of unnormalized image</p>\n</dd>\n<dt>max_v<span class=\"classifier\">int or float</span></dt><dd><p>maximum value of unnormalized image</p>\n</dd>\n</dl>\n</section>\n<section id=\"id88\">\n<h4>Returns<a class=\"headerlink\" href=\"#id88\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>np.ndarray</dt><dd><p>unnormalized image from range min_v to max_v</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"id89\">\n<h3>UNet3D<a class=\"headerlink\" href=\"#id89\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"id90\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.synb0.</span></span><span class=\"sig-name descname\"><span class=\"pre\">UNet3D</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">input_shape</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#id90\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd></dd></dl>\n\n</section>\n<section id=\"id91\">\n<h3>normalize<a class=\"headerlink\" href=\"#id91\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.utils.normalize\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.utils.</span></span><span class=\"sig-name descname\"><span class=\"pre\">normalize</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">min_v</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_v</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">None</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">new_min</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">-1</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">new_max</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">1</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.utils.normalize\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>normalization function</p>\n<section id=\"id92\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id92\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>image : np.ndarray\nmin_v : int or float (optional)</p>\n<blockquote>\n<div><p>minimum value range for normalization\nintensities below min_v will be clipped\nif None it is set to min value of image\nDefault : None</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>max_v<span class=\"classifier\">int or float (optional)</span></dt><dd><p>maximum value range for normalization\nintensities above max_v will be clipped\nif None it is set to max value of image\nDefault : None</p>\n</dd>\n<dt>new_min<span class=\"classifier\">int or float (optional)</span></dt><dd><p>new minimum value after normalization\nDefault : 0</p>\n</dd>\n<dt>new_max<span class=\"classifier\">int or float (optional)</span></dt><dd><p>new maximum value after normalization\nDefault : 1</p>\n</dd>\n</dl>\n</section>\n<section id=\"id93\">\n<h4>Returns<a class=\"headerlink\" href=\"#id93\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>np.ndarray</dt><dd><p>Normalized image from range new_min to new_max</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"id94\">\n<h3>unnormalize<a class=\"headerlink\" href=\"#id94\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.utils.unnormalize\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.utils.</span></span><span class=\"sig-name descname\"><span class=\"pre\">unnormalize</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">norm_min</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">norm_max</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">min_v</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">max_v</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.utils.unnormalize\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>unnormalization function</p>\n<section id=\"id95\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id95\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>image : np.ndarray\nnorm_min : int or float</p>\n<blockquote>\n<div><p>minimum value of normalized image</p>\n</div></blockquote>\n<dl class=\"simple\">\n<dt>norm_max<span class=\"classifier\">int or float</span></dt><dd><p>maximum value of normalized image</p>\n</dd>\n<dt>min_v<span class=\"classifier\">int or float</span></dt><dd><p>minimum value of unnormalized image</p>\n</dd>\n<dt>max_v<span class=\"classifier\">int or float</span></dt><dd><p>maximum value of unnormalized image</p>\n</dd>\n</dl>\n</section>\n<section id=\"id96\">\n<h4>Returns<a class=\"headerlink\" href=\"#id96\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>np.ndarray</dt><dd><p>unnormalized image from range min_v to max_v</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"set-logger-level\">\n<h3>set_logger_level<a class=\"headerlink\" href=\"#set-logger-level\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.utils.set_logger_level\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.utils.</span></span><span class=\"sig-name descname\"><span class=\"pre\">set_logger_level</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">log_level</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">logger</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.utils.set_logger_level\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Change the logger to one of the following:\nDEBUG, INFO, WARNING, CRITICAL, ERROR</p>\n<section id=\"id97\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id97\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>log_level<span class=\"classifier\">str</span></dt><dd><p>Log level for the logger</p>\n</dd>\n</dl>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"transform-img\">\n<h3>transform_img<a class=\"headerlink\" href=\"#transform-img\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.utils.transform_img\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.utils.</span></span><span class=\"sig-name descname\"><span class=\"pre\">transform_img</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">affine</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">init_shape</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">(256,</span> <span class=\"pre\">256,</span> <span class=\"pre\">256)</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">scale</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.utils.transform_img\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Function to reshape image as an input to the model</p>\n<section id=\"id98\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id98\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>image<span class=\"classifier\">np.ndarray</span></dt><dd><p>Image to transform to voxelspace</p>\n</dd>\n<dt>affine<span class=\"classifier\">np.ndarray</span></dt><dd><p>Affine matrix provided by the file</p>\n</dd>\n<dt>init_shape<span class=\"classifier\">tuple</span></dt><dd><p>Initial shape to transform the image to\nDefault is (256, 256, 256)</p>\n</dd>\n<dt>scale<span class=\"classifier\">float</span></dt><dd><p>How much we want to scale the image\nDefault is 2</p>\n</dd>\n</dl>\n</section>\n<section id=\"id99\">\n<h4>Returns<a class=\"headerlink\" href=\"#id99\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>transformed_img : np.ndarray</p>\n</section>\n</dd></dl>\n\n</section>\n<section id=\"recover-img\">\n<h3>recover_img<a class=\"headerlink\" href=\"#recover-img\" title=\"Permalink to this heading\">\u00b6</a></h3>\n<dl class=\"py function\">\n<dt class=\"sig sig-object py\" id=\"dipy.nn.utils.recover_img\">\n<span class=\"sig-prename descclassname\"><span class=\"pre\">dipy.nn.utils.</span></span><span class=\"sig-name descname\"><span class=\"pre\">recover_img</span></span><span class=\"sig-paren\">(</span><em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">image</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">affine</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">ori_shape</span></span></em>, <em class=\"sig-param\"><span class=\"n\"><span class=\"pre\">scale</span></span><span class=\"o\"><span class=\"pre\">=</span></span><span class=\"default_value\"><span class=\"pre\">2</span></span></em><span class=\"sig-paren\">)</span><a class=\"headerlink\" href=\"#dipy.nn.utils.recover_img\" title=\"Permalink to this definition\">\u00b6</a></dt>\n<dd><p>Function to recover image back to its original shape</p>\n<section id=\"id100\">\n<h4>Parameters<a class=\"headerlink\" href=\"#id100\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<dl class=\"simple\">\n<dt>image<span class=\"classifier\">np.ndarray</span></dt><dd><p>Image to recover</p>\n</dd>\n<dt>affine<span class=\"classifier\">np.ndarray</span></dt><dd><p>Affine matrix provided from transform_img</p>\n</dd>\n<dt>ori_shape<span class=\"classifier\">tuple</span></dt><dd><p>Original shape of image</p>\n</dd>\n<dt>scale<span class=\"classifier\">float</span></dt><dd><p>Scale that was used in transform_img\nDefault is 2</p>\n</dd>\n</dl>\n</section>\n<section id=\"id101\">\n<h4>Returns<a class=\"headerlink\" href=\"#id101\" title=\"Permalink to this heading\">\u00b6</a></h4>\n<p>recovered_img : np.ndarray</p>\n</section>\n</dd></dl>\n\n</section>\n</section>\n</section>\n", "metatags": "<meta name=\"generator\" content=\"Docutils 0.19: https://docutils.sourceforge.io/\" />\n", "rellinks": [["genindex", "General Index", "I", "index"], ["py-modindex", "Python Module Index", "", "modules"], ["reference/dipy.reconst", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">reconst</span></code>", "N", "next"], ["reference/dipy.io", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">io</span></code>", "P", "previous"]], "sourcename": "reference/dipy.nn.rst.txt", "toc": "<ul>\n<li><a class=\"reference internal\" href=\"#\"><code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.cnn_1d_denoising\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.cnn_1d_denoising</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#title-denoising-diffusion-weighted-imaging-data-using-cnn\">Title : Denoising diffusion weighted imaging data using CNN</a><ul>\n<li><a class=\"reference internal\" href=\"#reference\">Reference</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.evac\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.evac</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.histo_resdnn\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.histo_resdnn</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.model\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.model</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.synb0\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.synb0</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#module-dipy.nn.utils\">Module: <code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">nn.utils</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#cnn1ddenoiser\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.compile\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.compile()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.evaluate\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.evaluate()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.fit\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.fit()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.load_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.load_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.predict()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.save_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.save_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.summary\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.summary()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.cnn_1d_denoising.Cnn1DDenoiser.train_test_split\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Cnn1DDenoiser.train_test_split()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#block\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Block</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.Block\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Block</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.Block.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Block.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.Block.call\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Block.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#channelsum\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">ChannelSum</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.ChannelSum\"><code class=\"docutils literal notranslate\"><span class=\"pre\">ChannelSum</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.ChannelSum.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">ChannelSum.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.ChannelSum.call\"><code class=\"docutils literal notranslate\"><span class=\"pre\">ChannelSum.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#evacplus\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EVACPlus</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EVACPlus</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EVACPlus.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus.fetch_default_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EVACPlus.fetch_default_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus.load_model_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EVACPlus.load_model_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.EVACPlus.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EVACPlus.predict()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#logger\">logger</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.logger\"><code class=\"docutils literal notranslate\"><span class=\"pre\">logger()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#prepare-img\">prepare_img</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.prepare_img\"><code class=\"docutils literal notranslate\"><span class=\"pre\">prepare_img()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#init-model\">init_model</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.evac.init_model\"><code class=\"docutils literal notranslate\"><span class=\"pre\">init_model()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#historesdnn\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN\"><code class=\"docutils literal notranslate\"><span class=\"pre\">HistoResDNN</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">HistoResDNN.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.fetch_default_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">HistoResDNN.fetch_default_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.load_model_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">HistoResDNN.load_model_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.HistoResDNN.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">HistoResDNN.predict()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id36\">logger</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.histo_resdnn.logger\"><code class=\"docutils literal notranslate\"><span class=\"pre\">logger()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#singlelayerperceptron\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.evaluate\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron.evaluate()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.fit\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron.fit()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron.predict()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.SingleLayerPerceptron.summary\"><code class=\"docutils literal notranslate\"><span class=\"pre\">SingleLayerPerceptron.summary()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#multiplelayerpercepton\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.evaluate\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton.evaluate()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.fit\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton.fit()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton.predict()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.model.MultipleLayerPercepton.summary\"><code class=\"docutils literal notranslate\"><span class=\"pre\">MultipleLayerPercepton.summary()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#encoderblock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.EncoderBlock\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.EncoderBlock.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.EncoderBlock.call\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#decoderblock\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.DecoderBlock\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.DecoderBlock.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.DecoderBlock.call\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id61\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#id0\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#id62\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#id63\"><code class=\"docutils literal notranslate\"><span class=\"pre\">EncoderBlock.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id68\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#id69\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#id70\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#id71\"><code class=\"docutils literal notranslate\"><span class=\"pre\">DecoderBlock.call()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#synb0\"><code class=\"xref py py-class docutils literal notranslate\"><span class=\"pre\">Synb0</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Synb0</span></code></a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0.__init__\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Synb0.__init__()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0.fetch_default_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Synb0.fetch_default_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0.load_model_weights\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Synb0.load_model_weights()</span></code></a></li>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.Synb0.predict\"><code class=\"docutils literal notranslate\"><span class=\"pre\">Synb0.predict()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id84\">logger</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.logger\"><code class=\"docutils literal notranslate\"><span class=\"pre\">logger()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#unet3d\">UNet3D</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.UNet3D\"><code class=\"docutils literal notranslate\"><span class=\"pre\">UNet3D()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#normalize\">normalize</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.normalize\"><code class=\"docutils literal notranslate\"><span class=\"pre\">normalize()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#unnormalize\">unnormalize</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.synb0.unnormalize\"><code class=\"docutils literal notranslate\"><span class=\"pre\">unnormalize()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id89\">UNet3D</a><ul>\n<li><a class=\"reference internal\" href=\"#id90\"><code class=\"docutils literal notranslate\"><span class=\"pre\">UNet3D()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id91\">normalize</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.utils.normalize\"><code class=\"docutils literal notranslate\"><span class=\"pre\">normalize()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#id94\">unnormalize</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.utils.unnormalize\"><code class=\"docutils literal notranslate\"><span class=\"pre\">unnormalize()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#set-logger-level\">set_logger_level</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.utils.set_logger_level\"><code class=\"docutils literal notranslate\"><span class=\"pre\">set_logger_level()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#transform-img\">transform_img</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.utils.transform_img\"><code class=\"docutils literal notranslate\"><span class=\"pre\">transform_img()</span></code></a></li>\n</ul>\n</li>\n<li><a class=\"reference internal\" href=\"#recover-img\">recover_img</a><ul>\n<li><a class=\"reference internal\" href=\"#dipy.nn.utils.recover_img\"><code class=\"docutils literal notranslate\"><span class=\"pre\">recover_img()</span></code></a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n", "display_toc": true, "page_source_suffix": ".rst", "current_page_name": "reference/dipy.nn", "sidebars": ["localtoc.html", "relations.html", "sourcelink.html", "searchbox.html"], "customsidebar": null, "alabaster_version": "0.7.12"}